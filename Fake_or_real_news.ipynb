{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello there and welcome to this notebook!\n",
    "\n",
    "Here I am trying to distinguish between fake and real news and label them accordingly. \n",
    "I used 2 types of vectorizers (count and tfidf) as well as 3 types of classifiers (Naive Bayes, Linear Classifier and SVM). I know that we were supposed to use MaxEnt instead, but I found linear pretty usefull and the most successfull I must say. \n",
    "Also I tried 2 types of predictions: based on text and titles separately.\n",
    "\n",
    "I am submitting 2 files with predictions as well because I am not sure whether you will consider linear classifier appropriate for this task. prediction.csv is based on SVM classification while prediction1.csv is based on linear one.\n",
    "\n",
    "Sorry for inconvience and let's start! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing necessary packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download and explore the data we have here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Downloading the data\n",
    "train = pd.read_csv('fake_or_real_news_training.csv')\n",
    "test = pd.read_csv('fake_or_real_news_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df       ID                                              title  \\\n",
      "0   8476                       You Can Smell Hillary’s Fear   \n",
      "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4    875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label   X1   X2  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  NaN  NaN  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  NaN  NaN  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  NaN  NaN  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  NaN  NaN  \n",
      "4  It's primary day in New York and front-runners...  REAL  NaN  NaN  \n",
      " \n",
      "Test df       ID                                              title  \\\n",
      "0  10498  September New Homes Sales Rise——-Back To 1992 ...   \n",
      "1   2439  Why The Obamacare Doomsday Cult Can't Admit It...   \n",
      "2    864  Sanders, Cruz resist pressure after NY losses,...   \n",
      "3   4128  Surviving escaped prisoner likely fatigued and...   \n",
      "4    662  Clinton and Sanders neck and neck in Californi...   \n",
      "\n",
      "                                                text  \n",
      "0  September New Homes Sales Rise Back To 1992 Le...  \n",
      "1  But when Congress debated and passed the Patie...  \n",
      "2  The Bernie Sanders and Ted Cruz campaigns vowe...  \n",
      "3  Police searching for the second of two escaped...  \n",
      "4  No matter who wins California's 475 delegates ...  \n"
     ]
    }
   ],
   "source": [
    "#Head\n",
    "print('Train df' , train.head())\n",
    "print(' ')\n",
    "print('Test df', test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3999, 6)\n",
      "Test shape: (2321, 3)\n"
     ]
    }
   ],
   "source": [
    "#Shape\n",
    "print('Train shape:',train.shape)\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 6 columns):\n",
      "ID       3999 non-null int64\n",
      "title    3999 non-null object\n",
      "text     3999 non-null object\n",
      "label    3999 non-null object\n",
      "X1       33 non-null object\n",
      "X2       2 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 187.5+ KB\n",
      "Train info None\n",
      " \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2321 entries, 0 to 2320\n",
      "Data columns (total 3 columns):\n",
      "ID       2321 non-null int64\n",
      "title    2321 non-null object\n",
      "text     2321 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 54.5+ KB\n",
      "Test info None\n"
     ]
    }
   ],
   "source": [
    "#Info\n",
    "print('Train info', train.info())\n",
    "print(' ')\n",
    "print('Test info', test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to delete columns X1 and X2 based on the dataset info. X1 has only 33 non-null objects while X2 has just 2 of them. So I think these columns are not that valuable for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID                                              title  \\\n",
      "0   8476                       You Can Smell Hillary’s Fear   \n",
      "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4    875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n",
      " \n",
      "Train shape: (3999, 4)\n"
     ]
    }
   ],
   "source": [
    "#Discarding X1 and X2\n",
    "train = train[['ID', 'title', 'text', 'label']]\n",
    "print(train.head())\n",
    "print(' ')\n",
    "print('Train shape:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am starting to build classifiers that are based on the 'text' column of the train dataset. \n",
    "Firstly, I will split the dataset into train and test parts, than initialize 2 vectorizers and finally classify both vectorizers results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Labels and spliting\n",
    "y = train.label \n",
    "X_train, X_test, y_train, y_test = train_test_split(train['text'], y, test_size=0.33, random_state=13) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count vectorizer initialisation \n",
    "count_vector = CountVectorizer(stop_words='english') \n",
    "count_train = count_vector.fit_transform(X_train)\n",
    "count_test = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tfidf Vectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words=\"english\", max_df=0.7) \n",
    "tfidf_train = tfidf_vector.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vector.transform(X_test) \n",
    "final = tfidf_vector.transform(test['text']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count NB Classifier: initialisation and predition\n",
    "nb_class1 = MultinomialNB()\n",
    "nb_class1.fit(count_train, y_train) \n",
    "count_nb_pred = nb_class1.predict(count_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count NB score: 0.8833333333333333\n",
      "Confusion matrix \n",
      " [[572  92]\n",
      " [ 49 594]]\n"
     ]
    }
   ],
   "source": [
    "#Count NB Classifier: results\n",
    "score = metrics.accuracy_score(y_test, count_nb_pred) \n",
    "print('Count NB score:', score)\n",
    "\n",
    "con_mat = metrics.confusion_matrix(y_test, count_nb_pred, labels=['FAKE', 'REAL']) \n",
    "print('Confusion matrix', '\\n' ,con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tfidf NB classifier: initialisation and predition\n",
    "nb_class2 = MultinomialNB()\n",
    "nb_class2.fit(tfidf_train, y_train) \n",
    "tf_nb_pred = nb_class2.predict(tfidf_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf NB score: 0.796969696969697\n",
      "Confusion matrix \n",
      " [[418 246]\n",
      " [  9 634]]\n"
     ]
    }
   ],
   "source": [
    "#Tfidf NB classifier: results\n",
    "tf_score = metrics.accuracy_score(y_test, tf_nb_pred) \n",
    "print('Tfidf NB score:', tf_score)\n",
    "\n",
    "tf_con_mat = metrics.confusion_matrix(y_test, tf_nb_pred, labels=['FAKE', 'REAL']) \n",
    "print('Confusion matrix', '\\n', tf_con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR CLASSIFIER\n",
    "\n",
    "Idea of using linear classifier came to me after looking at this notebook:\n",
    "https://github.com/docketrun/Detecting-Fake-News-with-Scikit-Learn/blob/master/Attempting%20to%20detect%20fake%20news.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sazerland/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Linear count classifier\n",
    "linear_class1 = PassiveAggressiveClassifier(n_iter=200)\n",
    "linear_class1.fit(count_train, y_train)\n",
    "lin_count_pred = linear_class1.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear classifier count score: 0.875\n",
      "Confusion matrix \n",
      " [[583  76]\n",
      " [ 68 572]]\n"
     ]
    }
   ],
   "source": [
    "#Linear count classifier results\n",
    "lin_score = metrics.accuracy_score(y_test, lin_count_pred)\n",
    "print('Linear classifier count score:', lin_score)\n",
    "\n",
    "lin_con_mat = metrics.confusion_matrix(y_test, lin_count_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', lin_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sazerland/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Linear tfidf classifier\n",
    "linear_class2 = PassiveAggressiveClassifier(n_iter=200)\n",
    "linear_class2.fit(tfidf_train, y_train)\n",
    "lin_tf_pred = linear_class2.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear classifier tf score: 0.918939393939394\n",
      "Confusion matrix \n",
      " [[632  32]\n",
      " [ 62 581]]\n"
     ]
    }
   ],
   "source": [
    "#Linear tfidf classifier results\n",
    "lin_tf_score = metrics.accuracy_score(y_test, lin_tf_pred)\n",
    "print('Linear classifier tf score:', lin_tf_score)\n",
    "\n",
    "lin_con_mat = metrics.confusion_matrix(y_test, lin_tf_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', lin_con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM on count \n",
    "svm_class1 = svm.SVC(C=1, kernel='linear', gamma=1)\n",
    "svm_class1.fit(count_train, y_train)\n",
    "svm_count_pred = svm_class1.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM count score : 0.8204545454545454\n",
      "Confusion matrix \n",
      " [[559  68]\n",
      " [ 96 524]]\n"
     ]
    }
   ],
   "source": [
    "#SVM on count results\n",
    "svm_score = metrics.accuracy_score(y_test, svm_count_pred)\n",
    "print('SVM count score :', svm_score)\n",
    "\n",
    "svm_con_mat = metrics.confusion_matrix(y_test, svm_count_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', svm_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM on tfidf \n",
    "svm_class2 = svm.SVC(C=1, kernel='linear', gamma=1)\n",
    "svm_class2.fit(tfidf_train, y_train)\n",
    "svm_tfidf_pred = svm_class2.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM tf score: 0.9151515151515152\n",
      "Confusion matrix \n",
      " [[635  29]\n",
      " [ 70 573]]\n"
     ]
    }
   ],
   "source": [
    "#SVM on tfidf results\n",
    "svm_tf_score = metrics.accuracy_score(y_test, svm_tfidf_pred)\n",
    "print('SVM tf score:', svm_tf_score)\n",
    "\n",
    "svm_con_mat = metrics.confusion_matrix(y_test, svm_tfidf_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', svm_con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cells are dedicated to the title based classifiers. I use the same code as for the text based to build both vectorizers and classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Spliting\n",
    "X_t_train, X_t_test, y_t_train, y_t_test = train_test_split(train['title'], y, test_size=0.33, random_state=12) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count vectorizer initialisation \n",
    "count_vector = CountVectorizer(stop_words='english') \n",
    "count_t_train = count_vector.fit_transform(X_t_train)\n",
    "count_t_test = count_vector.transform(X_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tfidf Vectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words=\"english\", max_df=0.7) \n",
    "tfidf_t_train = tfidf_vector.fit_transform(X_t_train) \n",
    "tfidf_t_test = tfidf_vector.transform(X_t_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count NB Classifier: initialisation and predition\n",
    "nb_class3 = MultinomialNB()\n",
    "nb_class3.fit(count_t_train, y_t_train) \n",
    "count_nb_t_pred = nb_class3.predict(count_t_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count NB score: 0.7840909090909091\n",
      "Confusion matrix \n",
      " [[464 196]\n",
      " [ 82 571]]\n"
     ]
    }
   ],
   "source": [
    "#Count NB Classifier: results\n",
    "score_t = metrics.accuracy_score(y_t_test, count_nb_t_pred) \n",
    "print('Count NB score:', score_t)\n",
    "\n",
    "con_mat = metrics.confusion_matrix(y_t_test, count_nb_t_pred, labels=['FAKE', 'REAL']) \n",
    "print('Confusion matrix', '\\n' ,con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tfidf NB classifier: initialisation and predition\n",
    "nb_class3 = MultinomialNB()\n",
    "nb_class3.fit(tfidf_t_train, y_t_train) \n",
    "tf_nb_t_pred = nb_class3.predict(tfidf_t_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf NB score: 0.7704545454545455\n",
      "Confusion matrix \n",
      " [[450 210]\n",
      " [ 86 567]]\n"
     ]
    }
   ],
   "source": [
    "#Tfidf NB classifier: results\n",
    "tf_t_score = metrics.accuracy_score(y_t_test, tf_nb_t_pred) \n",
    "print('Tfidf NB score:', tf_t_score)\n",
    "\n",
    "tf_con_mat = metrics.confusion_matrix(y_t_test, tf_nb_t_pred, labels=['FAKE', 'REAL']) \n",
    "print('Confusion matrix', '\\n', tf_con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sazerland/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Linear count classifier\n",
    "linear_class3 = PassiveAggressiveClassifier(n_iter=100)\n",
    "linear_class3.fit(count_t_train, y_t_train)\n",
    "lin_count_t_pred = linear_class3.predict(count_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear classifier score: 0.7416666666666667\n",
      "Confusion matrix \n",
      " [[455 201]\n",
      " [126 524]]\n"
     ]
    }
   ],
   "source": [
    "#Linear count classifier results\n",
    "lin_t_score = metrics.accuracy_score(y_t_test, lin_count_t_pred)\n",
    "print('Linear classifier score:', lin_t_score)\n",
    "\n",
    "lin_con_mat = metrics.confusion_matrix(y_t_test, lin_count_t_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', lin_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sazerland/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Linear tfidf classifier\n",
    "linear_class4 = PassiveAggressiveClassifier(n_iter=200)\n",
    "linear_class4.fit(tfidf_t_train, y_t_train)\n",
    "lin_tf_t_pred = linear_class4.predict(tfidf_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear classifier score: 0.7583333333333333\n",
      "Confusion matrix \n",
      " [[471 187]\n",
      " [122 530]]\n"
     ]
    }
   ],
   "source": [
    "#Linear tfidf classifier results\n",
    "lin_tf_t_score = metrics.accuracy_score(y_t_test, lin_tf_t_pred)\n",
    "print('Linear classifier score:', lin_tf_t_score)\n",
    "\n",
    "lin_con_mat = metrics.confusion_matrix(y_t_test, lin_tf_t_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', lin_con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM on count \n",
    "svm_class3 = svm.SVC(C=1, kernel='linear', gamma=1)\n",
    "svm_class3.fit(count_t_train, y_t_train)\n",
    "svm_count_t_pred = svm_class3.predict(count_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score: 0.7674242424242425\n",
      "Confusion matrix \n",
      " [[481 179]\n",
      " [121 532]]\n"
     ]
    }
   ],
   "source": [
    "#SVM on count results\n",
    "svm_t_score = metrics.accuracy_score(y_t_test, svm_count_t_pred)\n",
    "print('SVM score:', svm_t_score)\n",
    "\n",
    "svm_con_mat = metrics.confusion_matrix(y_t_test, svm_count_t_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', svm_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM on tfidf \n",
    "svm_class4 = svm.SVC(C=1, kernel='linear', gamma=1)\n",
    "svm_class4.fit(tfidf_t_train, y_t_train)\n",
    "svm_tfidf_t_pred = svm_class4.predict(tfidf_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score: 0.7909090909090909\n",
      "Confusion matrix \n",
      " [[504 156]\n",
      " [113 540]]\n"
     ]
    }
   ],
   "source": [
    "#SVM on tfidf results\n",
    "svm_tf_t_score = metrics.accuracy_score(y_t_test, svm_tfidf_t_pred)\n",
    "print('SVM score:', svm_tf_t_score)\n",
    "\n",
    "svm_con_mat = metrics.confusion_matrix(y_t_test, svm_tfidf_t_pred, labels=['FAKE', 'REAL'])\n",
    "print('Confusion matrix', '\\n', svm_con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both results of text and title based classifiers will be compared next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text based classifiers\n",
      "Count NB score: 0.8833333333333333\n",
      "Tfidf NB score: 0.796969696969697\n",
      "Linear classifier count score: 0.875\n",
      "Linear classifier tf score: 0.918939393939394\n",
      "SVM count score : 0.8204545454545454\n",
      "SVM tf score: 0.9151515151515152\n",
      "\n",
      " Title based classifiers\n",
      "Count NB score: 0.7840909090909091\n",
      "Tfidf NB score: 0.7704545454545455\n",
      "Linear classifier count score: 0.7416666666666667\n",
      "Linear classifier tf score: 0.7583333333333333\n",
      "SVM count score: 0.7674242424242425\n",
      "SVM tf score: 0.7909090909090909\n"
     ]
    }
   ],
   "source": [
    "#Comparing scores\n",
    "print('Text based classifiers')\n",
    "print('Count NB score:', score)\n",
    "print('Tfidf NB score:', tf_score)\n",
    "print('Linear classifier count score:', lin_score)\n",
    "print('Linear classifier tf score:', lin_tf_score)\n",
    "print('SVM count score :', svm_score)\n",
    "print('SVM tf score:', svm_tf_score)\n",
    "\n",
    "print('\\n','Title based classifiers')\n",
    "print('Count NB score:', score_t)\n",
    "print('Tfidf NB score:', tf_t_score)\n",
    "print('Linear classifier count score:', lin_t_score)\n",
    "print('Linear classifier tf score:', lin_tf_t_score)\n",
    "print('SVM count score:', svm_t_score)\n",
    "print('SVM tf score:', svm_tf_t_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that count vectorizers work better with Naive Bayes classifier while tfidf vectorizers perform significantly better that count vectorizers using linear and SVM classifiers. \n",
    "\n",
    "We also observe that title based classifications accuracy is less then text based with all types of classifiers. Probably, this happens due to less amount of text in titles than in text of the news articles. \n",
    "\n",
    "For the final prediction I chose 2 text based classifiers build on top of tfidf vectorizer: linear and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear classifier\n",
    "lin_count_pred_test = linear_class1.predict(final)\n",
    "\n",
    "#SVM \n",
    "svm_tfidf_pred_test = svm_class2.predict(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   News_id prediction\n",
      "0    10498       FAKE\n",
      "1     2439       REAL\n",
      "2      864       REAL\n",
      "3     4128       REAL\n",
      "4      662       REAL\n",
      "(2321, 2) \n",
      "\n",
      "   News_id prediction\n",
      "0    10498       FAKE\n",
      "1     2439       REAL\n",
      "2      864       REAL\n",
      "3     4128       REAL\n",
      "4      662       REAL\n",
      "(2321, 2)\n"
     ]
    }
   ],
   "source": [
    "#Preparing predictions\n",
    "\n",
    "#Text based linear classifier on tfidf\n",
    "lin_df=pd.DataFrame({'News_id':test['ID'], 'prediction':lin_count_pred_test})\n",
    "print(lin_df.head())\n",
    "print(lin_df.shape, '\\n')\n",
    "\n",
    "#Text based SVM on tfidf\n",
    "svm_df=pd.DataFrame({'News_id':test['ID'], 'prediction':svm_tfidf_pred_test})\n",
    "print(svm_df.head())\n",
    "print(svm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving predictions\n",
    "lin_df.to_csv('prediction1.csv', index=False)\n",
    "svm_df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for reading this notebook! Please let me know if you have any questions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
